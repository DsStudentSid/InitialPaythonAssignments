{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecommendationEngine (4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DsStudentSid/InitialPaythonAssignments/blob/master/RecommendationEngine_(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QcETaD_bzGmX"
      },
      "source": [
        "<img src = 'https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true' width=\"240\" height=\"360\">\n",
        "\n",
        "# <center> <font color = red> RECOMMENDER SYSTEM </center>\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/start.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z5IPU0fWzGma"
      },
      "source": [
        "### INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "30tO-jnDzGmd"
      },
      "source": [
        "A **recommender system** or a **recommendation system** is a subclass of information filtering system that seeks to predict the \"rating\" or \"preference\" a user would give t an item. The primary focus is in commercial applications.<br><br>\n",
        "\n",
        "Recommender systems are utilized in a variety of areas, and are most commonly recognized as\n",
        "- Playlist generators for video and music services like Netflix, YouTube and SPotify, \n",
        "- Product recommenders for services such as Amazon or \n",
        "- Content recommenders for social media platforms such as Facebook and Twitter.\n",
        "    \n",
        "The system can operate using a single input, like music, or multiple inputs within and across platforms like news, books, search queries and ahve been developed to explore research articles and experts, collaborators, financial services and life insurance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pzz4F_BIzGmf"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/rec1.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZRZ0MLeszGmh"
      },
      "source": [
        "### STRUCTURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XC7XWYCyzGmj"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/rec.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qf8BK_ZRzGml"
      },
      "source": [
        "### CONTENT BASED APPROACH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQbTKeGpzGmn"
      },
      "source": [
        "This algorithm recommends products which are similar to the ones that a user has liked in the past.<br><br>\n",
        "__Consider the example of Netflix__ : \n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/rec_netflix.png\">\n",
        "- They save all the __information related to each user__ in a vector form called __profile vector__. \n",
        "- Profile vector contains the past behaviour of the user, i.e. the movies liked/disliked by the user and the ratings given by them. \n",
        "- All the __information related to movies__ is stored in another vector called __item vector__. \n",
        "- Item vector contais the details of each movies, like genre, cast, director, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLw_q_S8zGmp"
      },
      "source": [
        "#### HOW TO CREATE PROFILE VECTOR?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnjLs1kizGmr"
      },
      "source": [
        "- Each item will have an item profile\n",
        "- A table structure will list these properties\n",
        "- Comparing what and how many features match and collect scores\n",
        "- Recommend highest scored item\n",
        "- Code will be based on a algorithm, by given some item, the most similar item will be found.\n",
        "- Best scoring match will be provide to the user\n",
        "- This method relies on item features only, and not the user preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EL2KykNVzGmu"
      },
      "source": [
        "5 items profile are being constructed as an example, basd on top 5 sushi places in India. Sushi A, Sushi B, Sushi C, Sushi D and Sushi E.<br>\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco1.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTzDdYaQzGmv"
      },
      "source": [
        "Focusing on the featured words in the tables: Salmon, Tuna, Eel, Crab and Ramen.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco3.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hbWGtyTFzGmw"
      },
      "source": [
        "Similarities were being compared between 5 sushi places, to see how many matches. It showed:\n",
        "- 4 matches between Sushi A and Sushi B.\n",
        "- 5 matches between Sushi A and Sushi C.\n",
        "- 4 matches between Sushi A and Sushi D.\n",
        "- 3 matches between Sushi A and Sushi E.\n",
        "\n",
        "\n",
        "**The Best match for Sushi A is Sushi C**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zwK4_2sTzGmx"
      },
      "source": [
        "#### ONE HOT ENCODING "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0woUf2aXzGmz"
      },
      "source": [
        "Giving categorical data to a computer for processing is like talking to a tree in Mandarin and expecting a reply.<br>\n",
        "- A one hot encoding is a representation of categorical variables as binary vectors\n",
        "- It is first required that the categorical values be mapped to integer values.\n",
        "- Then, each integer value is respresented as a binary vector that is al zero values except the index of the integer, which is marked wit a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IK_25XduzGm0"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Source:</b> sklearn.preprocessing.OneHotEncoder\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HTPM3ztxzGm1"
      },
      "source": [
        "#### TF-IDF(Term Frequency - Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ht5gJGOMzGm3"
      },
      "source": [
        "- <font color = red>TF</font> - It signifies the occurrence of the word in a document.\n",
        "\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/tf.PNG\">\n",
        "\n",
        "- <font color = red>IDF</font> - It signifies the rarity of the word as the word occuring in the document.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/idf.PNG\">\n",
        "\n",
        "- <font color = red>TF-IDF</font> - It is a measure used to evaluate how important a word is to a document in a document corpus. The importance of word increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
        "\n",
        "\n",
        "TF-IDF is used mainly because of two reasons:\n",
        "- Suppose we search for \"the rise of AI\" on Google. It is certain that \"the\" will occur more frequently than \"AI\", but the relative importance of AI is higher.\n",
        "- In such case, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eignefcszGm4"
      },
      "source": [
        "#### COSINE SIMILARITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KIuT_ArHzGm5"
      },
      "source": [
        "The content based filtering algorithm finds the cosine of the angle between the profile vector and item vector, i.e. __cosine similarity__.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/cos.png\">\n",
        "\n",
        "Based on the cosine value, which ranges from __-1 to 1__, the movies are arranged in __descending order__ and one of the below two approaches is used for recommendations:\n",
        "\n",
        "- __Top-n approach__ : where the top n items are recommended.\n",
        "- __Rating scale approach__ : Where a threshold is set and all the items above that threshold are recommended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PWNEwoCRzGm6"
      },
      "source": [
        "### COLLABORATIVE FILTERING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-AuSRNZOzGm9"
      },
      "source": [
        "Collaborative filtering, also referred as social filtering, filters information by using the recommendations of other people.\n",
        "- It is based on idea that people who agreed in their evaluation of certain items in the past are likely to agree again in the future.\n",
        "- A person who wants to watch a movie for example, might ask for recommendations from others.\n",
        "- This information is used in the decision on which movie to see.\n",
        "\n",
        "\n",
        "This technique is commonly used to build personalized recommendations on the Web. Some popular websites that make use of the collabaorative filtering technology include <font color = red>**Amazon**, **Netflix**, **iTunes**, **LastFM**</font>.<br><br>\n",
        "In collaborative filtering, algorithms are used too make automatic predictions about a user's interests by compiling preferences from several users.<br><br>\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco.gif\">\n",
        "\n",
        "**Types of Collaborative filtering techniques**<br>\n",
        "- <font color = blue> Neighbourhood Base Approach</font>\n",
        "    - User Based\n",
        "    - Item Based\n",
        "    \n",
        "- <font color = blue>Model Based Approach</font>\n",
        "    - Nearest Neighbours\n",
        "    - Matrix Factorization(SVD)\n",
        "   \n",
        "- <font color = blue>Hybrid Models</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XZKGwuEuzGm-"
      },
      "source": [
        "#### NEIGHBOURHOOD BASED APPROACH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HmFY72mBzGnA"
      },
      "source": [
        "Recommender systems based on neighborhood automate the common principle of word-of-mouth, where one relies on the opinion of like-minded people or other trusted sources to evaluate the value of an item (movie, book, articles, album, etc.) according to his own preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-VxZyt29zGnA"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/rec13.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b0wgHN-szGnC"
      },
      "source": [
        "In the image below, there are three user rating on five movies.\n",
        "- The rating is from 1 to 5.\n",
        "- 1 indidcates that the user does not like the movie at all.\n",
        "- 5 indicated the user adores it.\n",
        "- ? means that the movie hasn't been rated by the user.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco5.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xAKjQg-LzGnD"
      },
      "source": [
        "The objective is to recommend top-N movies to a specific user, in here for Alex. In order to accomplish it, the ratings of movies that are not not rated by Alex need to be predicted first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BZ2JuKkQzGnE"
      },
      "source": [
        "#### User Based Collbaorative Filtering<br>\n",
        "**<font color = red>Step 1:</font> Claculating similarity between Alex and all other users.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DC_AEsNkzGnF"
      },
      "source": [
        "The calculation for the similarity between Alex and Bob can be derived as follows: \n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "sim(Alex, Bob) = \\frac{(4 * 5 + 2 * 3 + 4 * 3)}{[sqrt(4²+ 2²+ 4²) * sqrt(5² + 3² + 3²)]} = 0.97\\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J8cOwqa3zGnG"
      },
      "source": [
        "**<font color = red>Step 2:</font> Predict the ratings of the movies that are rated by Alex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PaFG9MZgzGnH"
      },
      "source": [
        "First k value is needs to be calculated by injecting the similarity values:\n",
        "\n",
        "\\begin{align}\n",
        "k = \\frac{1}{(0.97+1)} = 0.51\\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VtnUDevRzGnI"
      },
      "source": [
        "Now the movie Thor unrated by Alex can be worked by following calculation\n",
        "\n",
        "\\begin{align}\n",
        "R(Alex, Thor) =\\ k * [sim(Alex, Bob) * R(Bob, Thor)+ sim(Alex, Tom) * R(Tom, Thor)]= 0.51 * (0.97 * 4 + 1 * 4) = 4.02\\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XCOUOprjzGnK"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco6.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CbqAgs7KzGnL"
      },
      "source": [
        "**<font color = red>Step 3:</font> Select top-2 rated movies**<br>\n",
        "Since now the non-rated movie have been predicted, it is starightforward to find top-2 movies, which are Spider-man and Thor.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MiSxm8NKzGnM"
      },
      "source": [
        "#### Item-Based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JLD7GLlFzGnO"
      },
      "source": [
        "**<font color = red>Step 1:</font>Transpose the user-item matrix to the item-user matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BPAH1YKXzGnP"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco7.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EdMOl8A3zGnQ"
      },
      "source": [
        "**<font color = red>Step 2:</font> Calculate the similarity between any two items and fill up the item-item similarity matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bdd90V5hzGnR"
      },
      "source": [
        "Calculating similarity between Avenger and Star wars is demonstrated below:\n",
        "\n",
        "\\begin{align}\n",
        "sim(Avengers, Star wars) = \\frac{(4 * 2 + 5 * 3)}{[sqrt(4² + 5²) * sqrt(2² + 3²)]} = 0.99624059\\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7CX3sR8_zGnT"
      },
      "source": [
        "In the similar way, the item-item similarity matrix is calculated and filled in the below table, where 0 means the similarity between the two movies cannot be calculated due to **data sparsity**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "99mIWqtnzGnU"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco8.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwF_6MTAzGnV"
      },
      "source": [
        "**<font color = red>Step 3:</font> Predict the ratings of movies that are rated by Alex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y20xWxTSzGnV"
      },
      "source": [
        "After builidng the item-item similarity matrix, the rating can be injected which are not present as following:\n",
        "\n",
        "\\begin{align}\n",
        "R(Alex, Thor) = \\frac{(sim(Thor,Avengers) * R(Alex,Avengers) + sim(Thor, Iron man) * R(Alex, Iron man))}{(sim(Thor, Avengers) + sim(Thor, Iron man))} = 4\\\\\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kU-J5IM5zGnX"
      },
      "source": [
        "**<font color = red>Step 4:</font> Select top-2 rated movies for Alex**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXNvtXDxzGnX"
      },
      "source": [
        "It in now obvious here that three movies tie for second place, so the top-2 rated movies by Alex is comprised of Spider-man and one of the three tied movies - Avengers, Thor and Iron man.\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/reco9.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-JiWR62zGnY"
      },
      "source": [
        "#### MODEL BASED APPROACH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lvY43I2WzGnZ"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/modelbased.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DpDYbCYtzGnb"
      },
      "source": [
        "#### Clustering based approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZrQ9q3oxzGnd"
      },
      "source": [
        "In clustering based approach, the recommendations are transformed into a clustering like problem, where the similarity measure is based on \"How close two items are, while generating recommendations\"?\n",
        "- The measure for generating recommednation will be on the basis of similarity of two items like vector distance between these itmes.\n",
        "- The idea is same as that of memory based recommendations, using similarity between user/items and use them as weights to predict a rating from a user and an item.\n",
        "- In this the only difference is that similarities are calculated based on an unspervised learning model, rather than Pearson correlation or cosine similarity.\n",
        "- In this, we limit the number of similar users as k, which makes the system more scalable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPX8k9UdzGnf"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/clustering.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w5PbTvgzzGng"
      },
      "source": [
        "#### Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75NtxhAHzGng"
      },
      "source": [
        "**Most important technique in recommendation system**<br><br>\n",
        "- When a user gives feedback to a cerrtain movie they saw, this collection of feedback can be collected in the form of a matrix.\n",
        "- Each row represents each users,\n",
        "- Each column represents different movies.\n",
        "- The matrix will be sparse since not everyone is going to watch every movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5KxjHFLLzGnh"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/rec14.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LbmNGmsszGni"
      },
      "source": [
        "The idea behind such models is that the preference of a user can be determined by a small number of hidden factors. We can call these factors as **Embeddings**.<br><br>\n",
        "\n",
        "**Let's understand what is SVD**<br><br>\n",
        "Singular Value Decomposition(SVD) is a variability localization technique in which we represent data in form of matrix and then reduce the number of columns it has in order to maximize loss of dimensionality while minimizing loss of variability in the data being processed.<br>\n",
        "Why wouldn’t the data be lost? The answer for that question is the essence of SVD.\n",
        "\n",
        "Basically, SVD breaks a matrix into three other matrices called u, v, and d.\n",
        "\n",
        "1- A is the real matrix with m*n elements.\n",
        "\n",
        "2- U is an Orthogonal matrix with m*m elements\n",
        "\n",
        "3- V is an Orthogonal matrix with n*n elements.\n",
        "\n",
        "4- D is a diagonal matrix with m*n elements.\n",
        "\n",
        "Orthogonal matrix is a matrix that does not get its properties changed if multiplied by other numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vq7t4ocxzGnj"
      },
      "source": [
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/svd.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PobDFi6bzGnl"
      },
      "source": [
        "**What is the use of it?**<br><br>\n",
        "When we decompose our matrix A into (U, D, V), a few left-most columns of all three matrices represent almost all the information we need to recover our actual data. For example 92% of the information in just 5% of total columns which is a pretty good deal given that you have reduced the size of your data set tremendously.\n",
        "\n",
        "This means that SVD found some relation between all the columns of the matrix A and represented this same information with fewer columns.\n",
        "\n",
        "The curse of dimensionality is no longer able to affect your performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HVUR4qHXzGnm"
      },
      "source": [
        "**Matrix decompostion can be formulated as  an optimization problem with loss functions and constraints**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eDqnY8OFzGnm"
      },
      "source": [
        "We can understand embeddings as low dimensional hidden factors for items and users.<br>\n",
        "Let's say, we have 5 dimensional (D or n_factors = 5) embeddings for both items and users. Then for user-X and movie-A, we can say those 5 numbers might represent 5 different characterestics about the movies, like:\n",
        "- How much movie-A is sci-fi intense?\n",
        "- How recent is the movie?\n",
        "- How much special effects ar in movie?\n",
        "- How dialogue drive is the movie?\n",
        "\n",
        "\n",
        "Like wise some numbers in user embedding matrix might represents,\n",
        "- How much does user-X like sci-fi movies?\n",
        "- How much does user-X like recent movies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Km76fY01zGno"
      },
      "source": [
        "<img src= \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/Shubham's%20crap.PNG\">\n",
        "\n",
        "- Source: [https://www.youtube.com/watch?v=ZspR5PZemcs](https://www.youtube.com/watch?v=ZspR5PZemcs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8TxHEGGCzGno"
      },
      "source": [
        "### HYBRID MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3L7YokaXzGnr"
      },
      "source": [
        "Both content-based filtering and collaborative filtering have there strengths and weaknesses.<br>\n",
        "Content-based filtering:\n",
        "- Content description\n",
        "- Over-specialization\n",
        "- Subjective Domain problem\n",
        "\n",
        "Collabprative filtering:\n",
        "- Early rater problem\n",
        "- Sparsity\n",
        "- Data Scalability\n",
        "\n",
        "A system that combines content-based filtering and collaborative filtering could take advantage from both the representation of the content as well as similarities among users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tsaKtx3gzGns"
      },
      "source": [
        "**Collaboration via Content**<br><br>\n",
        "- In this, both the rated items and content of the items are used to construct a user profile. \n",
        "- The selection of terms which describe the content of the items is done using content-based techniques.\n",
        "- The weight of terms indicate how important they are to the users.\n",
        "\n",
        "Five terms and movie ratings:\n",
        "<img src = \"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/cvc.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JHvFcsUCzGnt"
      },
      "source": [
        "In here,\n",
        "- In collaborative, instead of determining the correlation with users ratings, term weights are used.\n",
        "- Unlike content based filtering, predicitions are based on the impressions of other users which could lead to recommendations outside the normal environment of a user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wpl2qcZbzGnu"
      },
      "source": [
        "### PROS AND CONS OF HYBRID MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9nlYhf_hzGnu"
      },
      "source": [
        "Pros:\n",
        "- Fast to implement\n",
        "- Fast to execute\n",
        "- Not much storage space required\n",
        "- Very successful in broad applications for large populations such as shelf layout in retail stores.\n",
        "\n",
        "Cons:\n",
        "- Not suitable of knowledge of prefernce change rapidly.\n",
        "- Sometime may lead to stupid recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d6qbbQlUzGnv"
      },
      "source": [
        "## The MovieLens Dataset\n",
        "One of the most common datasets that is available on the internet for building a Recommender System is the [MovieLens DataSet](https://grouplens.org/datasets/movielens/). This version of the dataset that I'm working with ([1M](https://grouplens.org/datasets/movielens/1m/)) contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
        "\n",
        "The data was collected by GroupLens researchers over various periods of time, depending on the size of the set. This 1M version was released on February 2003. Users were selected at random for inclusion. All users selected had rated at least 20 movies. Each user is represented by an id, and no other information is provided.\n",
        "\n",
        "The original data are contained in three files, [movies.dat](https://github.com/khanhnamle1994/movielens/blob/master/dat/movies.dat), [ratings.dat](https://github.com/khanhnamle1994/movielens/blob/master/dat/ratings.dat) and [users.dat](https://github.com/khanhnamle1994/movielens/blob/master/dat/users.dat). To make it easier to work with the data, we converted them into csv files.\n",
        "\n",
        "<img src =\"https://raw.githubusercontent.com/insaid2018/Term-4/master/images/movie.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O6y496dOzGnv"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_YRg_pMzGnx",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reading ratings file\n",
        "# Ignore the timestamp column\n",
        "ratings = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-4/master/Data/Assignment/ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
        "\n",
        "# Reading users file\n",
        "users = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-4/master/Data/Assignment/users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
        "\n",
        "# Reading movies file\n",
        "movies = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-4/master/Data/Assignment/movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bJWb-q8mzGn2"
      },
      "source": [
        "Now lets take a peak into the content of each file to understand them better.\n",
        "\n",
        "### Ratings Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ALtZ-bxGzGn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "02ae7caa-cf9a-43ed-d5d4-9d3259f97896"
      },
      "source": [
        "# Check the top 5 rows\n",
        "print(ratings.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  movie_id  rating\n",
            "0        1      1193       5\n",
            "1        1       661       3\n",
            "2        1       914       3\n",
            "3        1      3408       4\n",
            "4        1      2355       5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m1dI75z0zGn6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0cb92b55-1919-479b-8bb8-68f6b0bbe63f"
      },
      "source": [
        "# Check the file info\n",
        "print(ratings.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000209 entries, 0 to 1000208\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count    Dtype\n",
            "---  ------    --------------    -----\n",
            " 0   user_id   1000209 non-null  int64\n",
            " 1   movie_id  1000209 non-null  int64\n",
            " 2   rating    1000209 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 22.9 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QHEZlaMBzGn-"
      },
      "source": [
        "This confirms that there are 1M ratings for different user and movie combinations.\n",
        "\n",
        "### Users Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iOy7FqUczGn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2c332c8e-585f-4d96-8205-c3b40e958885"
      },
      "source": [
        "# Check the top 5 rows\n",
        "print(users.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id gender zipcode  age_desc              occ_desc\n",
            "0        1      F   48067  Under 18          K-12 student\n",
            "1        2      M   70072       56+         self-employed\n",
            "2        3      M   55117     25-34             scientist\n",
            "3        4      M   02460     45-49  executive/managerial\n",
            "4        5      M   55455     25-34                writer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KmSndzmDzGoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "7aeac731-8278-4a7d-fbba-932e70c3fa75"
      },
      "source": [
        "# Check the file info\n",
        "print(users.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6040 entries, 0 to 6039\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   user_id   6040 non-null   int64 \n",
            " 1   gender    6040 non-null   object\n",
            " 2   zipcode   6040 non-null   object\n",
            " 3   age_desc  6040 non-null   object\n",
            " 4   occ_desc  6040 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 236.1+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lpL6nzwwzGoG"
      },
      "source": [
        "This confirms that there are 6040 users and we have 5 features for each (unique user ID, gender, age, occupation and the zip code they are living in).\n",
        "\n",
        "### Movies Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OKbJxVESzGoH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "fa186f7c-55eb-4809-f55c-7bbb89cbe45b"
      },
      "source": [
        "# Check the top 5 rows\n",
        "print(movies.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   movie_id                               title                        genres\n",
            "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
            "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
            "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
            "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
            "4         5  Father of the Bride Part II (1995)                        Comedy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dn0DTq4zGoK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "07c0ab0b-a816-4481-fde9-f9c3c6c97614"
      },
      "source": [
        "# Check the file info\n",
        "print(movies.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3883 entries, 0 to 3882\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   movie_id  3883 non-null   int64 \n",
            " 1   title     3883 non-null   object\n",
            " 2   genres    3883 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 91.1+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ibERsMYjzGoN"
      },
      "source": [
        "This dataset contains attributes of the 3883 movies. There are 3 columns including the movie ID, their titles, and their genres. Genres are pipe-separated and are selected from 18 genres (Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUXUVeQPzGoO"
      },
      "source": [
        "## Data Exploration\n",
        "### Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eIk9BdplzGoP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c36df106-c9cd-435c-bc79-889e68aed389"
      },
      "source": [
        "# Get summary statistics of rating\n",
        "ratings['rating'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.000209e+06\n",
              "mean     3.581564e+00\n",
              "std      1.117102e+00\n",
              "min      1.000000e+00\n",
              "25%      3.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      4.000000e+00\n",
              "max      5.000000e+00\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KQsze5t1zGoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "dd488b1d-bdae-485f-d429-41cdf16d275b"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "sns.set(font_scale=1.5)\n",
        "%matplotlib inline\n",
        "\n",
        "# Display distribution of rating\n",
        "sns.distplot(ratings['rating'].fillna(ratings['rating'].median()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5a59a7a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXpuW6cizGoV"
      },
      "source": [
        "- It appears that users are quite generous in their ratings. \n",
        "- The mean rating is 3.58 on a scale of 5. Half the movies have a rating of 4 and 5.\n",
        "- Each user rated at least 20 movies, so I doubt the distribution could be caused just by chance variance in the quality of movies.\n",
        "\n",
        "Let's also take a look at a subset of 20 movies with the highest rating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wifspEz6zGoW"
      },
      "source": [
        "#### Join all 3 files into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZizbbv0zGoW",
        "colab": {}
      },
      "source": [
        "dataset = pd.merge(pd.merge(movies, ratings), users)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXoWnte1zGoZ"
      },
      "source": [
        "#### Display 20 movies with highest ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uimNZ5CjzGoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "c70bbfa4-11d1-4ea5-824c-48501cefc92f"
      },
      "source": [
        "dataset[['title','genres','rating']].sort_values('rating', ascending=False).head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489283</th>\n",
              "      <td>American Beauty (1999)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489259</th>\n",
              "      <td>Election (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489257</th>\n",
              "      <td>Matrix, The (1999)</td>\n",
              "      <td>Action|Sci-Fi|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489256</th>\n",
              "      <td>Dead Ringers (1988)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489237</th>\n",
              "      <td>Rushmore (1998)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489236</th>\n",
              "      <td>Simple Plan, A (1998)</td>\n",
              "      <td>Crime|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489226</th>\n",
              "      <td>Hands on a Hard Body (1996)</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489224</th>\n",
              "      <td>Pleasantville (1998)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489212</th>\n",
              "      <td>Say Anything... (1989)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489207</th>\n",
              "      <td>Beetlejuice (1988)</td>\n",
              "      <td>Comedy|Fantasy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489190</th>\n",
              "      <td>Roger &amp; Me (1989)</td>\n",
              "      <td>Comedy|Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489172</th>\n",
              "      <td>Buffalo 66 (1998)</td>\n",
              "      <td>Action|Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489171</th>\n",
              "      <td>Out of Sight (1998)</td>\n",
              "      <td>Action|Crime|Romance</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489170</th>\n",
              "      <td>I Went Down (1997)</td>\n",
              "      <td>Action|Comedy|Crime</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489168</th>\n",
              "      <td>Opposite of Sex, The (1998)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489157</th>\n",
              "      <td>Good Will Hunting (1997)</td>\n",
              "      <td>Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489152</th>\n",
              "      <td>Fast, Cheap &amp; Out of Control (1997)</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489149</th>\n",
              "      <td>L.A. Confidential (1997)</td>\n",
              "      <td>Crime|Film-Noir|Mystery|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489145</th>\n",
              "      <td>Contact (1997)</td>\n",
              "      <td>Drama|Sci-Fi</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title  ... rating\n",
              "0                          Toy Story (1995)  ...      5\n",
              "489283               American Beauty (1999)  ...      5\n",
              "489259                      Election (1999)  ...      5\n",
              "489257                   Matrix, The (1999)  ...      5\n",
              "489256                  Dead Ringers (1988)  ...      5\n",
              "489237                      Rushmore (1998)  ...      5\n",
              "489236                Simple Plan, A (1998)  ...      5\n",
              "489226          Hands on a Hard Body (1996)  ...      5\n",
              "489224                 Pleasantville (1998)  ...      5\n",
              "489212               Say Anything... (1989)  ...      5\n",
              "489207                   Beetlejuice (1988)  ...      5\n",
              "489190                    Roger & Me (1989)  ...      5\n",
              "489172                    Buffalo 66 (1998)  ...      5\n",
              "489171                  Out of Sight (1998)  ...      5\n",
              "489170                   I Went Down (1997)  ...      5\n",
              "489168          Opposite of Sex, The (1998)  ...      5\n",
              "489157             Good Will Hunting (1997)  ...      5\n",
              "489152  Fast, Cheap & Out of Control (1997)  ...      5\n",
              "489149             L.A. Confidential (1997)  ...      5\n",
              "489145                       Contact (1997)  ...      5\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Voz_DbOnzGoc"
      },
      "source": [
        "### Genres\n",
        "The genres variable will surely be important while building the recommendation engines since it describes the content of the film (i.e. Animation, Horror, Sci-Fi). A basic assumption is that films in the same genre should have similar contents. I'll attempt to see exactly which genres are the most popular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R-Mv2tNjzGod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5ff765f0-4b14-4319-e98f-d14f995b4516"
      },
      "source": [
        "# Make a census of the genre keywords\n",
        "genre_labels = set()\n",
        "for s in movies['genres'].str.split('|').values:\n",
        "    genre_labels = genre_labels.union(set(s))\n",
        "\n",
        "# Function that counts the number of times each of the genre keywords appear\n",
        "def count_word(dataset, ref_col, census):\n",
        "    keyword_count = dict()\n",
        "    for s in census: \n",
        "        keyword_count[s] = 0\n",
        "    for census_keywords in dataset[ref_col].str.split('|'):        \n",
        "        if type(census_keywords) == float and pd.isnull(census_keywords): \n",
        "            continue        \n",
        "        for s in [s for s in census_keywords if s in census]: \n",
        "            if pd.notnull(s): \n",
        "                keyword_count[s] += 1\n",
        "    #______________________________________________________________________\n",
        "    # convert the dictionary in a list to sort the keywords by frequency\n",
        "    keyword_occurences = []\n",
        "    for k,v in keyword_count.items():\n",
        "        keyword_occurences.append([k,v])\n",
        "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
        "    return keyword_occurences, keyword_count\n",
        "\n",
        "# Calling this function gives access to a list of genre keywords which are sorted by decreasing frequency\n",
        "keyword_occurences, dum = count_word(movies, 'genres', genre_labels)\n",
        "keyword_occurences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Drama', 1603],\n",
              " ['Comedy', 1200],\n",
              " ['Action', 503],\n",
              " ['Thriller', 492],\n",
              " ['Romance', 471]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xr9MtzKzGog"
      },
      "source": [
        "The top 5 genres are, in that respect order: \n",
        "1. Drama, \n",
        "2. Comedy, \n",
        "3. Action, \n",
        "4. Thriller\n",
        "5. Romance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ordzrZhfzGog"
      },
      "source": [
        "## Content-Based Recommendation Model\n",
        "\n",
        "### Implementation\n",
        "We will build a Content-Based Recommendation Engine that computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre. \n",
        "- To do so, we will make use of the file **movies.csv**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7b1IEZk4zGoi",
        "colab": {}
      },
      "source": [
        "# Break up the big genre string into a string array\n",
        "movies['genres'] = movies['genres'].str.split('|')\n",
        "\n",
        "\n",
        "# Convert genres to string value\n",
        "movies['genres'] = movies['genres'].fillna(\"\").astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-A1EZAuszGok"
      },
      "source": [
        "- We do not have a quantitative metric to judge our machine's performance so this will have to be done qualitatively. \n",
        "- In order to do so, we'll use **TfidfVectorizer** function from **scikit-learn**, which transforms text to feature vectors that can be used as input to estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brxKF8C_zGok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2098f178-f116-4418-8e3c-ba5e8df34457"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
        "tfidf_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3883, 127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e7rOxbnAzGom"
      },
      "source": [
        "- Further we will be using the **Cosine Similarity** to calculate a numeric quantity that denotes the similarity between two movies. \n",
        "- Since we have used the TF-IDF Vectorizer, calculating the Dot Product will directly give us the Cosine Similarity Score.\n",
        "- Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities since it is much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-iQ4w35zGon",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ec4613fa-a616-4fe7-aeb6-cb12743fe8e3"
      },
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "cosine_sim[:4, :4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.14193614, 0.09010857, 0.1056164 ],\n",
              "       [0.14193614, 1.        , 0.        , 0.        ],\n",
              "       [0.09010857, 0.        , 1.        , 0.1719888 ],\n",
              "       [0.1056164 , 0.        , 0.1719888 , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nPXeqx-qzGoq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1e147a9-39f6-4a25-8f33-603f62055f78"
      },
      "source": [
        "cosine_sim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3883, 3883)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GL_9Mr29zGou"
      },
      "source": [
        "- Now have a pairwise cosine similarity matrix for all the movies in the dataset. \n",
        "- Create a function that returns the 20 most similar movies based on the cosine similarity score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8AXHs4pzGou"
      },
      "source": [
        "#### Build a 1-dimensional array with movie titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s-Mqd2TEzGov",
        "colab": {}
      },
      "source": [
        "titles = movies['title']\n",
        "indices = pd.Series(movies.index, index=movies['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1x61Q-XTzGox"
      },
      "source": [
        "#### Function that get movie recommendations based on the cosine similarity score of movie genres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ql7g2p07zGox",
        "colab": {}
      },
      "source": [
        "def genre_recommendations(title):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:21]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return titles.iloc[movie_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ynlgukRYzGoz"
      },
      "source": [
        "Let's try and get the top recommendations for a few movies and see how good the recommendations are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUW2-U9BzGo0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1ed4fec6-5e0d-4685-f416-42ee9ccd9636"
      },
      "source": [
        "genre_recommendations('Good Will Hunting (1997)').head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25                                       Othello (1995)\n",
              "26                                  Now and Then (1995)\n",
              "29    Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
              "30                               Dangerous Minds (1995)\n",
              "35                              Dead Man Walking (1995)\n",
              "39                      Cry, the Beloved Country (1995)\n",
              "42                                   Restoration (1995)\n",
              "52                                      Lamerica (1994)\n",
              "54                                       Georgia (1995)\n",
              "56                         Home for the Holidays (1995)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXV5MuAnzGo3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "259dcb26-467a-450b-f7a2-0a93603c1b44"
      },
      "source": [
        "genre_recommendations('Toy Story (1995)').head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1050            Aladdin and the King of Thieves (1996)\n",
              "2072                          American Tail, An (1986)\n",
              "2073        American Tail: Fievel Goes West, An (1991)\n",
              "2285                         Rugrats Movie, The (1998)\n",
              "2286                              Bug's Life, A (1998)\n",
              "3045                                Toy Story 2 (1999)\n",
              "3542                             Saludos Amigos (1943)\n",
              "3682                                Chicken Run (2000)\n",
              "3685    Adventures of Rocky and Bullwinkle, The (2000)\n",
              "236                              Goofy Movie, A (1995)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xPcxASEmzGo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "140861cc-1872-4f7f-c469-9487f7c0225b"
      },
      "source": [
        "genre_recommendations('Saving Private Ryan (1998)').head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "461            Heaven & Earth (1993)\n",
              "1204        Full Metal Jacket (1987)\n",
              "1214     Boat, The (Das Boot) (1981)\n",
              "1222                    Glory (1989)\n",
              "1545                G.I. Jane (1997)\n",
              "1959      Saving Private Ryan (1998)\n",
              "2358       Thin Red Line, The (1998)\n",
              "2993         Longest Day, The (1962)\n",
              "3559            Flying Tigers (1942)\n",
              "3574    Fighting Seabees, The (1944)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SH5aS6-7zGo-"
      },
      "source": [
        "As we can see, we have quite a decent list of recommendation for **Good Will Hunting** (Drama), **Toy Story** (Animation, Children's, Comedy), and **Saving Private Ryan** (Action, Thriller, War).\n",
        "\n",
        "Overall, here are the pros of using content-based recommendation:\n",
        "* No need for data on other users, thus no cold-start or sparsity problems.\n",
        "* Can recommend to users with unique tastes.\n",
        "* Can recommend new & unpopular items.\n",
        "* Can provide explanations for recommended items by listing content-features that caused an item to be recommended (in this case, movie genres)\n",
        "\n",
        "However, there are some cons of using this approach:\n",
        "* Finding the appropriate features is hard.\n",
        "* Does not recommend items outside a user's content profile.\n",
        "* Unable to exploit quality judgments of other users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhhhfXiNzGo-"
      },
      "source": [
        "## Collaborative Filtering Recommendation Model\n",
        "\n",
        "### Implementation\n",
        "We will use the file **ratings.csv** first as it contains User ID, Movie IDs and Ratings. \n",
        "\n",
        "These three elements are all we need for determining the similarity of the users based on their ratings for a particular movie.\n",
        "\n",
        "First, we will do some quick data processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xtG3ZaoXzGo_",
        "colab": {}
      },
      "source": [
        "# Fill NaN values in user_id and movie_id column with 0\n",
        "ratings['user_id'] = ratings['user_id'].fillna(0)\n",
        "ratings['movie_id'] = ratings['movie_id'].fillna(0)\n",
        "\n",
        "# Replace NaN values in rating column with average of all values\n",
        "ratings['rating'] = ratings['rating'].fillna(ratings['rating'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OFfhnlmczGpB"
      },
      "source": [
        "Due to the limited computing power, we will build the recommender system using only a subset of the ratings. \n",
        "\n",
        "We will take a random sample of 20,000 ratings (2%) from the 1M ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_mZlqo1wzGpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2f9853df-45ad-401e-82dd-cffa60b66ae1"
      },
      "source": [
        "# Randomly sample 1% of the ratings dataset\n",
        "small_data = ratings.sample(frac=0.02)\n",
        "\n",
        "# Check the sample info\n",
        "print(small_data.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20004 entries, 969761 to 606682\n",
            "Data columns (total 3 columns):\n",
            "user_id     20004 non-null int64\n",
            "movie_id    20004 non-null int64\n",
            "rating      20004 non-null int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 625.1 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c4-WL_lYzGpE"
      },
      "source": [
        "### Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MUr3SkUczGpE",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection as cv\n",
        "train_data, test_data = cv.train_test_split(small_data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X3Xdm-PwzGpH"
      },
      "source": [
        "Now we need to create a user-item matrix.\n",
        "\n",
        " Since, we have splitted the data into testing and training, we need to create two matrices. \n",
        " \n",
        " The training matrix contains 80% of the ratings and the testing matrix contains 20% of the ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmvmZz8GzGpH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "702a7c75-3f4a-4067-bf79-df16d3849939"
      },
      "source": [
        "# Create two user-item matrices, one for training and another for testing\n",
        "train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
        "test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
        "\n",
        "# Check their shape\n",
        "print(train_data_matrix.shape)\n",
        "print(test_data_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16003, 3)\n",
            "(4001, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_nKB7n4tzGpJ"
      },
      "source": [
        "Now we will use the **pairwise_distances** function from sklearn to calculate the [Pearson Correlation Coefficient](https://stackoverflow.com/questions/1838806/euclidean-distance-vs-pearson-correlation-vs-cosine-similarity). \n",
        "\n",
        "This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZbbZApczGpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "bed392b6-e663-4669-c5be-c708a3229db4"
      },
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "# User Similarity Matrix\n",
        "user_correlation = 1 - pairwise_distances(train_data, metric='correlation')\n",
        "user_correlation[np.isnan(user_correlation)] = 0\n",
        "print(user_correlation[:4, :4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.28977382 0.84061431 0.98650602]\n",
            " [0.28977382 1.         0.76198346 0.44256399]\n",
            " [0.84061431 0.76198346 1.         0.91795012]\n",
            " [0.98650602 0.44256399 0.91795012 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LX4c73zqzGpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "43b0d821-51ab-4e77-cbce-1f80db27f665"
      },
      "source": [
        "# Item Similarity Matrix\n",
        "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
        "item_correlation[np.isnan(item_correlation)] = 0\n",
        "print(item_correlation[:4, :4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.         -0.01416629  0.01320726]\n",
            " [-0.01416629  1.         -0.05008897]\n",
            " [ 0.01320726 -0.05008897  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LIFm5Vx_zGpQ"
      },
      "source": [
        "- Using the similarity matrix, we can now predict the ratings that were not included with the data. \n",
        "- Using these predictions, we can then compare them with the test data to attempt to validate the quality of our recommender model.\n",
        "\n",
        "For the user-user CF case, we will look at the similarity between 2 users (A and B, for example) as weights that are multiplied by the ratings of a similar user B (corrected for the average rating of that user). \n",
        "- We also need to normalize it so that the ratings stay between 1 and 5 and, as a final step, sum the average ratings for the user that we are trying to predict. \n",
        "- The idea here is that some users may tend always to give high or low ratings to all movies. \n",
        "- The relative difference in the ratings that these users give is more important than the absolute values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O91PlnLizGpS"
      },
      "source": [
        "#### Function to predict ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gn4hhyvczGpS",
        "colab": {}
      },
      "source": [
        "def predict(ratings, similarity, type='user'):\n",
        "    if type == 'user':\n",
        "        mean_user_rating = ratings.mean(axis=1)\n",
        "        # Use np.newaxis so that mean_user_rating has same format as ratings\n",
        "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
        "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
        "    elif type == 'item':\n",
        "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SOHvXv2SzGpT"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BSc1T1WzGpU",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def rmse(pred, actual):\n",
        "    # Ignore nonzero terms.\n",
        "    pred = pred[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(pred, actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kx1V2oVEzGpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "63a6fe57-d2f5-4c25-a5ab-610cd0afc9d1"
      },
      "source": [
        "# Predict ratings on the training data with both similarity score\n",
        "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
        "item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
        "\n",
        "# RMSE on the test data\n",
        "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
        "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-based CF RMSE: 1411.166218651134\n",
            "Item-based CF RMSE: 1629.562684217173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QrPN0JROzGpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e986aa87-91fd-4efd-db46-2e1d417cc66c"
      },
      "source": [
        "# RMSE on the train data\n",
        "print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
        "print('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-based CF RMSE: 693.3462256071465\n",
            "Item-based CF RMSE: 126.59159391752551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IS5ofZ6mzGpa"
      },
      "source": [
        "RMSE of training of model is a metric which measure how much the signal and the noise is explained by the model. \n",
        "\n",
        "We can notice that our RMSE is quite big. We might have overfitted the training data.\n",
        "\n",
        "Overall, Memory-based Collaborative Filtering is easy to implement and produce reasonable prediction quality. \n",
        "\n",
        "However, there are some drawback of this approach:\n",
        "\n",
        "* It doesn't address the well-known cold-start problem, that is when new user or new item enters the system. \n",
        "* It can't deal with sparse data, meaning it's hard to find users that have rated the same items.\n",
        "* It suffers when new users or items that don't have any ratings enter the system.\n",
        "* It tends to recommend popular items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q7aSaEkSzGpa"
      },
      "source": [
        "### Implementing Singular Vector Decoposition\n",
        "\n",
        "#### Using Ratings data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kQoCYknVzGpb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bb2dbae-5d24-4077-88c7-13298612f199"
      },
      "source": [
        "n_users = ratings.user_id.unique().shape[0]\n",
        "n_movies = ratings.movie_id.unique().shape[0]\n",
        "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_movies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users = 6040 | Number of movies = 3706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x61S5aMGzGpc"
      },
      "source": [
        "- We want the format of my ratings matrix to be one row per user and one column per movie. \n",
        "- We'll pivot *ratings* to get that and call the new variable *Ratings* (with a capital *R)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z0wDvZlYzGpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "214863e2-a60c-4ce9-8bea-7ad46068ae65"
      },
      "source": [
        "Ratings = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "Ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>movie_id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>3913</th>\n",
              "      <th>3914</th>\n",
              "      <th>3915</th>\n",
              "      <th>3916</th>\n",
              "      <th>3917</th>\n",
              "      <th>3918</th>\n",
              "      <th>3919</th>\n",
              "      <th>3920</th>\n",
              "      <th>3921</th>\n",
              "      <th>3922</th>\n",
              "      <th>3923</th>\n",
              "      <th>3924</th>\n",
              "      <th>3925</th>\n",
              "      <th>3926</th>\n",
              "      <th>3927</th>\n",
              "      <th>3928</th>\n",
              "      <th>3929</th>\n",
              "      <th>3930</th>\n",
              "      <th>3931</th>\n",
              "      <th>3932</th>\n",
              "      <th>3933</th>\n",
              "      <th>3934</th>\n",
              "      <th>3935</th>\n",
              "      <th>3936</th>\n",
              "      <th>3937</th>\n",
              "      <th>3938</th>\n",
              "      <th>3939</th>\n",
              "      <th>3940</th>\n",
              "      <th>3941</th>\n",
              "      <th>3942</th>\n",
              "      <th>3943</th>\n",
              "      <th>3944</th>\n",
              "      <th>3945</th>\n",
              "      <th>3946</th>\n",
              "      <th>3947</th>\n",
              "      <th>3948</th>\n",
              "      <th>3949</th>\n",
              "      <th>3950</th>\n",
              "      <th>3951</th>\n",
              "      <th>3952</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3706 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "movie_id  1     2     3     4     5     ...  3948  3949  3950  3951  3952\n",
              "user_id                                 ...                              \n",
              "1          5.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0\n",
              "2          0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0\n",
              "3          0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0\n",
              "4          0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0\n",
              "5          0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0\n",
              "\n",
              "[5 rows x 3706 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SF2VUHFPzGpf"
      },
      "source": [
        "We need to de-normalize the data (normalize by each users mean) and convert it from a dataframe to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D293LnqXzGpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "71af6224-d5fd-446c-ab73-7ee119002528"
      },
      "source": [
        "R = Ratings.as_matrix()\n",
        "user_ratings_mean = np.mean(R, axis=1)\n",
        "Ratings_demeaned = R - user_ratings_mean.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pNuZuqJ8zGpg"
      },
      "source": [
        "- With the ratings matrix properly formatted and normalized, we can do some dimensionality reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fE2a55X4zGph"
      },
      "source": [
        "## Model-Based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q4deX-vBzGph"
      },
      "source": [
        "### Using K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FHrzmnwSzGph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0f228ca9-7a79-4d6b-b2a1-bf014c708e42"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "model_knn.fit(Ratings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_OYKBdvzGpj"
      },
      "source": [
        "#### Testing our model and making some recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhR7ulQnzGpk",
        "colab": {},
        "outputId": "e5266c66-9719-4f37-d252-34501b0d3b21"
      },
      "source": [
        "Ratings.index[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPlCRqj5zGpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "08bf3e8a-7aad-46a0-8670-12377f01c026"
      },
      "source": [
        "query_index = np.random.choice(Ratings.shape[0])\n",
        "distances, indices = model_knn.kneighbors(Ratings.iloc[query_index, :].values.reshape(1, -1), n_neighbors=6)\n",
        "\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i == 0:\n",
        "        print('Recommendation for {0}:\\n'.format(Ratings.index[query_index]))\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, Ratings.index[indices.flatten()[i]],distances.flatten()[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recommendation for 2026:\n",
            "\n",
            "1: 4083, with distance of 0.606175060399706:\n",
            "2: 2795, with distance of 0.6162852107812516:\n",
            "3: 4245, with distance of 0.6171672613681551:\n",
            "4: 5112, with distance of 0.6262744701072415:\n",
            "5: 1884, with distance of 0.632532003831718:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3amJ4zypzGpn"
      },
      "source": [
        "#### Checking sparisty level of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "00kkUQdizGpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5140b845-dcd5-48cd-dd1a-7d501b4a89b9"
      },
      "source": [
        "sparsity = round(1.0 - len(ratings) / float(n_users * n_movies), 3)\n",
        "print('The sparsity level of MovieLens1M dataset is ' +  str(sparsity * 100) + '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sparsity level of MovieLens1M dataset is 95.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hXhGBmcPzGpq"
      },
      "source": [
        "### Setting Up SVD\n",
        "Scipy and Numpy both have functions to do the singular value decomposition. \n",
        "\n",
        "We're going to use the Scipy function *svds* because it let's us choose how many latent factors we want to use to approximate the original ratings matrix (instead of having to truncate it after)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZABVEe8zGpr",
        "colab": {}
      },
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "U, sigma, Vt = svds(Ratings_demeaned, k = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfsSGlg1zGps"
      },
      "source": [
        "As we're going to leverage matrix multiplication to get predictions, we'll convert the $\\Sigma$ (now are values) to the diagonal matrix form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eyzaqA5VzGps",
        "colab": {}
      },
      "source": [
        "sigma = np.diag(sigma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PpheuSc0zGpv"
      },
      "source": [
        "### Making Predictions from the Decomposed Matrices\n",
        "We now have everything we need to make movie ratings predictions for every user. \n",
        "\n",
        "We can do it all at once by following the math and matrix multiply $U$, $\\Sigma$, and $V^{T}$ back to get the rank $k=50$ approximation of $A$.\n",
        "\n",
        "But first, we need to add the user means back to get the actual star ratings prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NCo5dxWDzGpv",
        "colab": {}
      },
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RiVjXf2KzGpx"
      },
      "source": [
        "With the predictions matrix for every user, we can build a function to recommend movies for any user. \n",
        "\n",
        "We return the list of movies the user has already rated, for the sake of comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CDhTfldvzGpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "f2bc27fe-f4e3-4f69-8498-93244de55c14"
      },
      "source": [
        "preds = pd.DataFrame(all_user_predicted_ratings, columns = Ratings.columns)\n",
        "preds.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>movie_id</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>3913</th>\n",
              "      <th>3914</th>\n",
              "      <th>3915</th>\n",
              "      <th>3916</th>\n",
              "      <th>3917</th>\n",
              "      <th>3918</th>\n",
              "      <th>3919</th>\n",
              "      <th>3920</th>\n",
              "      <th>3921</th>\n",
              "      <th>3922</th>\n",
              "      <th>3923</th>\n",
              "      <th>3924</th>\n",
              "      <th>3925</th>\n",
              "      <th>3926</th>\n",
              "      <th>3927</th>\n",
              "      <th>3928</th>\n",
              "      <th>3929</th>\n",
              "      <th>3930</th>\n",
              "      <th>3931</th>\n",
              "      <th>3932</th>\n",
              "      <th>3933</th>\n",
              "      <th>3934</th>\n",
              "      <th>3935</th>\n",
              "      <th>3936</th>\n",
              "      <th>3937</th>\n",
              "      <th>3938</th>\n",
              "      <th>3939</th>\n",
              "      <th>3940</th>\n",
              "      <th>3941</th>\n",
              "      <th>3942</th>\n",
              "      <th>3943</th>\n",
              "      <th>3944</th>\n",
              "      <th>3945</th>\n",
              "      <th>3946</th>\n",
              "      <th>3947</th>\n",
              "      <th>3948</th>\n",
              "      <th>3949</th>\n",
              "      <th>3950</th>\n",
              "      <th>3951</th>\n",
              "      <th>3952</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.288861</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>-0.195080</td>\n",
              "      <td>-0.018843</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>-0.176604</td>\n",
              "      <td>-0.074120</td>\n",
              "      <td>0.141358</td>\n",
              "      <td>-0.059553</td>\n",
              "      <td>-0.195950</td>\n",
              "      <td>0.512867</td>\n",
              "      <td>-0.089172</td>\n",
              "      <td>0.310181</td>\n",
              "      <td>-0.002005</td>\n",
              "      <td>-0.052401</td>\n",
              "      <td>-0.189827</td>\n",
              "      <td>0.238360</td>\n",
              "      <td>0.006466</td>\n",
              "      <td>-0.099315</td>\n",
              "      <td>-0.069682</td>\n",
              "      <td>-0.321492</td>\n",
              "      <td>0.111577</td>\n",
              "      <td>0.034795</td>\n",
              "      <td>0.320576</td>\n",
              "      <td>-0.118217</td>\n",
              "      <td>-0.012647</td>\n",
              "      <td>0.065573</td>\n",
              "      <td>-0.098318</td>\n",
              "      <td>0.064081</td>\n",
              "      <td>-0.005914</td>\n",
              "      <td>0.091936</td>\n",
              "      <td>0.180563</td>\n",
              "      <td>-0.009566</td>\n",
              "      <td>2.641693</td>\n",
              "      <td>-0.012495</td>\n",
              "      <td>0.765179</td>\n",
              "      <td>0.019784</td>\n",
              "      <td>0.002917</td>\n",
              "      <td>0.053079</td>\n",
              "      <td>0.014856</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018810</td>\n",
              "      <td>-0.018782</td>\n",
              "      <td>0.022249</td>\n",
              "      <td>0.227852</td>\n",
              "      <td>-0.067653</td>\n",
              "      <td>-0.046039</td>\n",
              "      <td>-0.023574</td>\n",
              "      <td>-0.019405</td>\n",
              "      <td>-0.005116</td>\n",
              "      <td>-0.032921</td>\n",
              "      <td>-0.008259</td>\n",
              "      <td>-0.019157</td>\n",
              "      <td>0.007527</td>\n",
              "      <td>-0.008687</td>\n",
              "      <td>-0.025630</td>\n",
              "      <td>-0.013563</td>\n",
              "      <td>0.015240</td>\n",
              "      <td>-0.044665</td>\n",
              "      <td>-0.009568</td>\n",
              "      <td>-0.043549</td>\n",
              "      <td>-0.003131</td>\n",
              "      <td>-0.008221</td>\n",
              "      <td>-0.005948</td>\n",
              "      <td>0.031885</td>\n",
              "      <td>-0.003424</td>\n",
              "      <td>-0.001159</td>\n",
              "      <td>-0.002124</td>\n",
              "      <td>-0.002827</td>\n",
              "      <td>0.010393</td>\n",
              "      <td>-0.001068</td>\n",
              "      <td>0.027807</td>\n",
              "      <td>0.001640</td>\n",
              "      <td>0.026395</td>\n",
              "      <td>-0.022024</td>\n",
              "      <td>-0.085415</td>\n",
              "      <td>0.403529</td>\n",
              "      <td>0.105579</td>\n",
              "      <td>0.031912</td>\n",
              "      <td>0.050450</td>\n",
              "      <td>0.088910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.744716</td>\n",
              "      <td>0.169659</td>\n",
              "      <td>0.335418</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.022475</td>\n",
              "      <td>1.353050</td>\n",
              "      <td>0.051426</td>\n",
              "      <td>0.071258</td>\n",
              "      <td>0.161601</td>\n",
              "      <td>1.567246</td>\n",
              "      <td>0.772656</td>\n",
              "      <td>0.046179</td>\n",
              "      <td>-0.054562</td>\n",
              "      <td>0.042344</td>\n",
              "      <td>0.048390</td>\n",
              "      <td>0.347313</td>\n",
              "      <td>1.074905</td>\n",
              "      <td>-0.099782</td>\n",
              "      <td>0.008163</td>\n",
              "      <td>0.250869</td>\n",
              "      <td>2.186638</td>\n",
              "      <td>0.018789</td>\n",
              "      <td>-0.002199</td>\n",
              "      <td>0.218934</td>\n",
              "      <td>0.824475</td>\n",
              "      <td>0.139274</td>\n",
              "      <td>-0.007135</td>\n",
              "      <td>0.053071</td>\n",
              "      <td>-0.156952</td>\n",
              "      <td>0.044739</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>0.453298</td>\n",
              "      <td>-0.007484</td>\n",
              "      <td>0.920325</td>\n",
              "      <td>0.016566</td>\n",
              "      <td>1.335129</td>\n",
              "      <td>-0.015066</td>\n",
              "      <td>-0.045602</td>\n",
              "      <td>0.034649</td>\n",
              "      <td>0.122010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.042363</td>\n",
              "      <td>-0.137822</td>\n",
              "      <td>-0.112071</td>\n",
              "      <td>0.380783</td>\n",
              "      <td>-0.036273</td>\n",
              "      <td>-0.016174</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>-0.148021</td>\n",
              "      <td>-0.017614</td>\n",
              "      <td>-0.033474</td>\n",
              "      <td>0.086133</td>\n",
              "      <td>0.008153</td>\n",
              "      <td>-0.126819</td>\n",
              "      <td>0.109208</td>\n",
              "      <td>0.001798</td>\n",
              "      <td>0.151866</td>\n",
              "      <td>0.014118</td>\n",
              "      <td>0.032897</td>\n",
              "      <td>0.005764</td>\n",
              "      <td>0.042259</td>\n",
              "      <td>0.022404</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.010556</td>\n",
              "      <td>0.137181</td>\n",
              "      <td>-0.042184</td>\n",
              "      <td>0.006759</td>\n",
              "      <td>-0.005789</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.016013</td>\n",
              "      <td>-0.056502</td>\n",
              "      <td>-0.013733</td>\n",
              "      <td>-0.010580</td>\n",
              "      <td>0.062576</td>\n",
              "      <td>-0.016248</td>\n",
              "      <td>0.155790</td>\n",
              "      <td>-0.418737</td>\n",
              "      <td>-0.101102</td>\n",
              "      <td>-0.054098</td>\n",
              "      <td>-0.140188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.818824</td>\n",
              "      <td>0.456136</td>\n",
              "      <td>0.090978</td>\n",
              "      <td>-0.043037</td>\n",
              "      <td>-0.025694</td>\n",
              "      <td>-0.158617</td>\n",
              "      <td>-0.131778</td>\n",
              "      <td>0.098977</td>\n",
              "      <td>0.030551</td>\n",
              "      <td>0.735470</td>\n",
              "      <td>-0.023476</td>\n",
              "      <td>0.034796</td>\n",
              "      <td>0.065942</td>\n",
              "      <td>0.008661</td>\n",
              "      <td>0.110348</td>\n",
              "      <td>-0.002952</td>\n",
              "      <td>-0.122061</td>\n",
              "      <td>0.063974</td>\n",
              "      <td>0.061033</td>\n",
              "      <td>0.081799</td>\n",
              "      <td>0.329471</td>\n",
              "      <td>0.149579</td>\n",
              "      <td>0.095352</td>\n",
              "      <td>-0.161493</td>\n",
              "      <td>0.022545</td>\n",
              "      <td>-0.009284</td>\n",
              "      <td>-0.002677</td>\n",
              "      <td>-0.142710</td>\n",
              "      <td>0.012345</td>\n",
              "      <td>-0.085331</td>\n",
              "      <td>0.076139</td>\n",
              "      <td>-0.355795</td>\n",
              "      <td>-0.008579</td>\n",
              "      <td>1.046871</td>\n",
              "      <td>-0.088946</td>\n",
              "      <td>0.383583</td>\n",
              "      <td>-0.018144</td>\n",
              "      <td>-0.038618</td>\n",
              "      <td>0.113984</td>\n",
              "      <td>0.006942</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007233</td>\n",
              "      <td>-0.047221</td>\n",
              "      <td>0.066474</td>\n",
              "      <td>-0.179455</td>\n",
              "      <td>0.097428</td>\n",
              "      <td>0.034113</td>\n",
              "      <td>0.008098</td>\n",
              "      <td>-0.024784</td>\n",
              "      <td>-0.012749</td>\n",
              "      <td>-0.007394</td>\n",
              "      <td>-0.017220</td>\n",
              "      <td>0.004719</td>\n",
              "      <td>0.113348</td>\n",
              "      <td>-0.074943</td>\n",
              "      <td>-0.145795</td>\n",
              "      <td>0.128619</td>\n",
              "      <td>0.112567</td>\n",
              "      <td>0.045500</td>\n",
              "      <td>-0.018027</td>\n",
              "      <td>-0.058946</td>\n",
              "      <td>-0.002770</td>\n",
              "      <td>-0.035276</td>\n",
              "      <td>-0.008085</td>\n",
              "      <td>0.132182</td>\n",
              "      <td>-0.017005</td>\n",
              "      <td>0.014383</td>\n",
              "      <td>0.006598</td>\n",
              "      <td>-0.006217</td>\n",
              "      <td>-0.000342</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.040481</td>\n",
              "      <td>-0.005301</td>\n",
              "      <td>0.012832</td>\n",
              "      <td>0.029349</td>\n",
              "      <td>0.020866</td>\n",
              "      <td>0.121532</td>\n",
              "      <td>0.076205</td>\n",
              "      <td>0.012345</td>\n",
              "      <td>0.015148</td>\n",
              "      <td>-0.109956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.408057</td>\n",
              "      <td>-0.072960</td>\n",
              "      <td>0.039642</td>\n",
              "      <td>0.089363</td>\n",
              "      <td>0.041950</td>\n",
              "      <td>0.237753</td>\n",
              "      <td>-0.049426</td>\n",
              "      <td>0.009467</td>\n",
              "      <td>0.045469</td>\n",
              "      <td>-0.111370</td>\n",
              "      <td>-0.375831</td>\n",
              "      <td>0.068658</td>\n",
              "      <td>0.011199</td>\n",
              "      <td>0.069699</td>\n",
              "      <td>-0.037529</td>\n",
              "      <td>-0.238788</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>-0.043418</td>\n",
              "      <td>0.053152</td>\n",
              "      <td>0.078237</td>\n",
              "      <td>0.357185</td>\n",
              "      <td>-0.096005</td>\n",
              "      <td>-0.028243</td>\n",
              "      <td>-0.067169</td>\n",
              "      <td>0.246164</td>\n",
              "      <td>-0.020379</td>\n",
              "      <td>0.034461</td>\n",
              "      <td>-0.022225</td>\n",
              "      <td>-0.012327</td>\n",
              "      <td>0.009182</td>\n",
              "      <td>0.014730</td>\n",
              "      <td>0.215893</td>\n",
              "      <td>-0.019687</td>\n",
              "      <td>-0.293933</td>\n",
              "      <td>-0.011511</td>\n",
              "      <td>0.145326</td>\n",
              "      <td>-0.029213</td>\n",
              "      <td>0.030029</td>\n",
              "      <td>-0.045409</td>\n",
              "      <td>-0.030684</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015077</td>\n",
              "      <td>-0.030208</td>\n",
              "      <td>0.028357</td>\n",
              "      <td>-0.072643</td>\n",
              "      <td>-0.135727</td>\n",
              "      <td>-0.053318</td>\n",
              "      <td>-0.012962</td>\n",
              "      <td>-0.054465</td>\n",
              "      <td>0.005870</td>\n",
              "      <td>-0.018048</td>\n",
              "      <td>-0.006836</td>\n",
              "      <td>-0.008222</td>\n",
              "      <td>-0.027214</td>\n",
              "      <td>-0.071677</td>\n",
              "      <td>-0.094072</td>\n",
              "      <td>-0.010745</td>\n",
              "      <td>-0.103191</td>\n",
              "      <td>-0.031297</td>\n",
              "      <td>-0.023920</td>\n",
              "      <td>-0.015053</td>\n",
              "      <td>-0.017914</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.024299</td>\n",
              "      <td>-0.057678</td>\n",
              "      <td>-0.111450</td>\n",
              "      <td>-0.015473</td>\n",
              "      <td>-0.007123</td>\n",
              "      <td>-0.007416</td>\n",
              "      <td>-0.011508</td>\n",
              "      <td>-0.010038</td>\n",
              "      <td>0.008571</td>\n",
              "      <td>-0.005425</td>\n",
              "      <td>-0.008500</td>\n",
              "      <td>-0.003417</td>\n",
              "      <td>-0.083982</td>\n",
              "      <td>0.094512</td>\n",
              "      <td>0.057557</td>\n",
              "      <td>-0.026050</td>\n",
              "      <td>0.014841</td>\n",
              "      <td>-0.034224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.574272</td>\n",
              "      <td>0.021239</td>\n",
              "      <td>-0.051300</td>\n",
              "      <td>0.246884</td>\n",
              "      <td>-0.032406</td>\n",
              "      <td>1.552281</td>\n",
              "      <td>-0.199630</td>\n",
              "      <td>-0.014920</td>\n",
              "      <td>-0.060498</td>\n",
              "      <td>0.450512</td>\n",
              "      <td>-0.251178</td>\n",
              "      <td>0.012337</td>\n",
              "      <td>-0.084051</td>\n",
              "      <td>0.258937</td>\n",
              "      <td>0.016570</td>\n",
              "      <td>0.980536</td>\n",
              "      <td>1.267869</td>\n",
              "      <td>0.275619</td>\n",
              "      <td>-0.008139</td>\n",
              "      <td>-0.038832</td>\n",
              "      <td>1.849627</td>\n",
              "      <td>0.107649</td>\n",
              "      <td>-0.168424</td>\n",
              "      <td>0.386541</td>\n",
              "      <td>1.790343</td>\n",
              "      <td>0.192379</td>\n",
              "      <td>-0.054356</td>\n",
              "      <td>0.267566</td>\n",
              "      <td>1.027817</td>\n",
              "      <td>0.374665</td>\n",
              "      <td>-0.010445</td>\n",
              "      <td>1.947980</td>\n",
              "      <td>0.017468</td>\n",
              "      <td>2.784035</td>\n",
              "      <td>0.274397</td>\n",
              "      <td>1.422393</td>\n",
              "      <td>0.040553</td>\n",
              "      <td>0.022926</td>\n",
              "      <td>1.345800</td>\n",
              "      <td>0.104507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075475</td>\n",
              "      <td>0.330767</td>\n",
              "      <td>0.150470</td>\n",
              "      <td>-0.261636</td>\n",
              "      <td>0.085163</td>\n",
              "      <td>-0.014229</td>\n",
              "      <td>-0.029247</td>\n",
              "      <td>0.124172</td>\n",
              "      <td>0.092875</td>\n",
              "      <td>0.061895</td>\n",
              "      <td>0.034757</td>\n",
              "      <td>0.054386</td>\n",
              "      <td>0.047055</td>\n",
              "      <td>0.048403</td>\n",
              "      <td>0.082926</td>\n",
              "      <td>0.129035</td>\n",
              "      <td>-0.174646</td>\n",
              "      <td>0.102727</td>\n",
              "      <td>0.024732</td>\n",
              "      <td>0.047280</td>\n",
              "      <td>0.017818</td>\n",
              "      <td>0.041451</td>\n",
              "      <td>0.041595</td>\n",
              "      <td>-0.007138</td>\n",
              "      <td>-0.080448</td>\n",
              "      <td>0.018639</td>\n",
              "      <td>0.034068</td>\n",
              "      <td>0.026941</td>\n",
              "      <td>0.035905</td>\n",
              "      <td>0.024459</td>\n",
              "      <td>0.110151</td>\n",
              "      <td>0.046010</td>\n",
              "      <td>0.006934</td>\n",
              "      <td>-0.015940</td>\n",
              "      <td>-0.050080</td>\n",
              "      <td>-0.052539</td>\n",
              "      <td>0.507189</td>\n",
              "      <td>0.033830</td>\n",
              "      <td>0.125706</td>\n",
              "      <td>0.199244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3706 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "movie_id      1         2         3     ...      3950      3951      3952\n",
              "0         4.288861  0.143055 -0.195080  ...  0.031912  0.050450  0.088910\n",
              "1         0.744716  0.169659  0.335418  ... -0.101102 -0.054098 -0.140188\n",
              "2         1.818824  0.456136  0.090978  ...  0.012345  0.015148 -0.109956\n",
              "3         0.408057 -0.072960  0.039642  ... -0.026050  0.014841 -0.034224\n",
              "4         1.574272  0.021239 -0.051300  ...  0.033830  0.125706  0.199244\n",
              "\n",
              "[5 rows x 3706 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "coxQr7IOzGpz"
      },
      "source": [
        "Now we'll write a function to return the movies with the highest predicted rating that the specified user hasn't already rated. \n",
        "\n",
        "Though we didn't use any explicit movie content features (such as genre or title), we'll merge in that information to get a more complete picture of the recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HcCiiVjBzGpz",
        "colab": {}
      },
      "source": [
        "def recommend_movies(predictions, userID, movies, original_ratings, num_recommendations):\n",
        "    \n",
        "    # Get and sort the user's predictions\n",
        "    user_row_number = userID - 1 # User ID starts at 1, not 0\n",
        "    sorted_user_predictions = preds.iloc[user_row_number].sort_values(ascending=False) # User ID starts at 1\n",
        "    \n",
        "    # Get the user's data and merge in the movie information.\n",
        "    user_data = original_ratings[original_ratings.user_id == (userID)]\n",
        "    user_full = (user_data.merge(movies, how = 'left', left_on = 'movie_id', right_on = 'movie_id').\n",
        "                     sort_values(['rating'], ascending=False)\n",
        "                 )\n",
        "\n",
        "    print('User {0} has already rated {1} movies.'.format(userID, user_full.shape[0]))\n",
        "    print('Recommending highest {0} predicted ratings movies not already rated.'.format(num_recommendations))\n",
        "    \n",
        "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
        "    recommendations = (movies[~movies['movie_id'].isin(user_full['movie_id'])].\n",
        "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
        "               left_on = 'movie_id',\n",
        "               right_on = 'movie_id').\n",
        "         rename(columns = {user_row_number: 'Predictions'}).\n",
        "         sort_values('Predictions', ascending = False).\n",
        "                       iloc[:num_recommendations, :-1]\n",
        "                      )\n",
        "\n",
        "    return user_full, recommendations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yZEpac4RzGp2"
      },
      "source": [
        "Let's try to recommend 20 movies for user with ID 1310."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7WajgxHzGp3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b2720f70-ae67-4143-b726-2547e3b6c67e"
      },
      "source": [
        "already_rated, predictions = recommend_movies(preds, 1310, movies, ratings, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User 1310 has already rated 24 movies.\n",
            "Recommending highest 20 predicted ratings movies not already rated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1uAIJWzkzGp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "d6c9c624-2f2f-41c2-eb13-3aa922bb97d8"
      },
      "source": [
        "# Top 10 movies that User 1310 has rated \n",
        "already_rated.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1310</td>\n",
              "      <td>2248</td>\n",
              "      <td>5</td>\n",
              "      <td>Say Anything... (1989)</td>\n",
              "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1310</td>\n",
              "      <td>2620</td>\n",
              "      <td>5</td>\n",
              "      <td>This Is My Father (1998)</td>\n",
              "      <td>['Drama', 'Romance']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1310</td>\n",
              "      <td>3683</td>\n",
              "      <td>5</td>\n",
              "      <td>Blood Simple (1984)</td>\n",
              "      <td>['Drama', 'Film-Noir']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1310</td>\n",
              "      <td>1704</td>\n",
              "      <td>5</td>\n",
              "      <td>Good Will Hunting (1997)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1310</td>\n",
              "      <td>1293</td>\n",
              "      <td>5</td>\n",
              "      <td>Gandhi (1982)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1310</td>\n",
              "      <td>3101</td>\n",
              "      <td>4</td>\n",
              "      <td>Fatal Attraction (1987)</td>\n",
              "      <td>['Thriller']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1310</td>\n",
              "      <td>1343</td>\n",
              "      <td>4</td>\n",
              "      <td>Cape Fear (1991)</td>\n",
              "      <td>['Thriller']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1310</td>\n",
              "      <td>2000</td>\n",
              "      <td>4</td>\n",
              "      <td>Lethal Weapon (1987)</td>\n",
              "      <td>['Action', 'Comedy', 'Crime', 'Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1310</td>\n",
              "      <td>3526</td>\n",
              "      <td>4</td>\n",
              "      <td>Parenthood (1989)</td>\n",
              "      <td>['Comedy', 'Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1310</td>\n",
              "      <td>3360</td>\n",
              "      <td>4</td>\n",
              "      <td>Hoosiers (1986)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id  ...                                  genres\n",
              "5      1310  ...          ['Comedy', 'Drama', 'Romance']\n",
              "6      1310  ...                    ['Drama', 'Romance']\n",
              "7      1310  ...                  ['Drama', 'Film-Noir']\n",
              "15     1310  ...                               ['Drama']\n",
              "1      1310  ...                               ['Drama']\n",
              "12     1310  ...                            ['Thriller']\n",
              "11     1310  ...                            ['Thriller']\n",
              "20     1310  ...  ['Action', 'Comedy', 'Crime', 'Drama']\n",
              "18     1310  ...                     ['Comedy', 'Drama']\n",
              "17     1310  ...                               ['Drama']\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RloRT2aazGp7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "ed733de1-abe3-49c9-9956-676e84714da6"
      },
      "source": [
        "# Top 20 movies that User 1310 hopefully will enjoy\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1674</td>\n",
              "      <td>Witness (1985)</td>\n",
              "      <td>['Drama', 'Romance', 'Thriller']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1880</th>\n",
              "      <td>1961</td>\n",
              "      <td>Rain Man (1988)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>1210</td>\n",
              "      <td>Star Wars: Episode VI - Return of the Jedi (1983)</td>\n",
              "      <td>['Action', 'Adventure', 'Romance', 'Sci-Fi', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1216</th>\n",
              "      <td>1242</td>\n",
              "      <td>Glory (1989)</td>\n",
              "      <td>['Action', 'Drama', 'War']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>1225</td>\n",
              "      <td>Amadeus (1984)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1273</th>\n",
              "      <td>1302</td>\n",
              "      <td>Field of Dreams (1989)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>1246</td>\n",
              "      <td>Dead Poets Society (1989)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1881</th>\n",
              "      <td>1962</td>\n",
              "      <td>Driving Miss Daisy (1989)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1877</th>\n",
              "      <td>1957</td>\n",
              "      <td>Chariots of Fire (1981)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>2020</td>\n",
              "      <td>Dangerous Liaisons (1988)</td>\n",
              "      <td>['Drama', 'Romance']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>1259</td>\n",
              "      <td>Stand by Me (1986)</td>\n",
              "      <td>['Adventure', 'Comedy', 'Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3011</th>\n",
              "      <td>3098</td>\n",
              "      <td>Natural, The (1984)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2112</th>\n",
              "      <td>2194</td>\n",
              "      <td>Untouchables, The (1987)</td>\n",
              "      <td>['Action', 'Crime', 'Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1876</th>\n",
              "      <td>1956</td>\n",
              "      <td>Ordinary People (1980)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>1296</td>\n",
              "      <td>Room with a View, A (1986)</td>\n",
              "      <td>['Drama', 'Romance']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2267</th>\n",
              "      <td>2352</td>\n",
              "      <td>Big Chill, The (1983)</td>\n",
              "      <td>['Comedy', 'Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>1307</td>\n",
              "      <td>When Harry Met Sally... (1989)</td>\n",
              "      <td>['Comedy', 'Romance']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1165</th>\n",
              "      <td>1186</td>\n",
              "      <td>Sex, Lies, and Videotape (1989)</td>\n",
              "      <td>['Drama']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1222</td>\n",
              "      <td>Full Metal Jacket (1987)</td>\n",
              "      <td>['Action', 'Drama', 'War']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>2919</td>\n",
              "      <td>Year of Living Dangerously (1982)</td>\n",
              "      <td>['Drama', 'Romance']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      movie_id  ...                                             genres\n",
              "1618      1674  ...                   ['Drama', 'Romance', 'Thriller']\n",
              "1880      1961  ...                                          ['Drama']\n",
              "1187      1210  ...  ['Action', 'Adventure', 'Romance', 'Sci-Fi', '...\n",
              "1216      1242  ...                         ['Action', 'Drama', 'War']\n",
              "1202      1225  ...                                          ['Drama']\n",
              "1273      1302  ...                                          ['Drama']\n",
              "1220      1246  ...                                          ['Drama']\n",
              "1881      1962  ...                                          ['Drama']\n",
              "1877      1957  ...                                          ['Drama']\n",
              "1938      2020  ...                               ['Drama', 'Romance']\n",
              "1233      1259  ...                   ['Adventure', 'Comedy', 'Drama']\n",
              "3011      3098  ...                                          ['Drama']\n",
              "2112      2194  ...                       ['Action', 'Crime', 'Drama']\n",
              "1876      1956  ...                                          ['Drama']\n",
              "1268      1296  ...                               ['Drama', 'Romance']\n",
              "2267      2352  ...                                ['Comedy', 'Drama']\n",
              "1278      1307  ...                              ['Comedy', 'Romance']\n",
              "1165      1186  ...                                          ['Drama']\n",
              "1199      1222  ...                         ['Action', 'Drama', 'War']\n",
              "2833      2919  ...                               ['Drama', 'Romance']\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TV81qcrkzGp9"
      },
      "source": [
        "- It's good to see that, although we didn't actually use the genre of the movie as a feature, the truncated matrix factorization features \"picked up\" on the underlying tastes and preferences of the user. \n",
        "- We've recommended some comedy, drama, and romance movies - all of which were genres of some of this user's top rated movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nlzFT_szGp9"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "We will use the [Surprise](https://pypi.python.org/pypi/scikit-surprise) library that provided various ready-to-use powerful prediction algorithms including (SVD) to evaluate its RMSE (Root Mean Squared Error) on the MovieLens dataset. It is a Python scikit building and analyzing recommender systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpuHTxqWOaJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3d49d1bd-a09b-452c-f3c6-4a01f3fbe044"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.17.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1678236 sha256=b5730d229d27be03da02cb215929fcb65718e7bc701adb06454e361dfa5ba7a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHcar3ilPbvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries from Surprise package\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import SVD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xa2M0tQQV_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Reader\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load ratings dataset with Dataset\n",
        "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwqUeasRxOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the SVD algorithm.\n",
        "svd = SVD()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLSon5YSGd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "e6ee96b3-389f-4bfa-cc4a-b125b5bf11d9"
      },
      "source": [
        "# Run 5-fold cross-validation and print results\n",
        "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8711  0.8744  0.8750  0.8759  0.8743  0.8741  0.0016  \n",
            "MAE (testset)     0.6831  0.6869  0.6861  0.6875  0.6859  0.6859  0.0015  \n",
            "Fit time          40.98   41.60   41.65   41.74   42.18   41.63   0.38    \n",
            "Test time         1.97    2.01    1.76    2.03    1.74    1.90    0.13    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (40.98330211639404,\n",
              "  41.600950956344604,\n",
              "  41.65361976623535,\n",
              "  41.73626732826233,\n",
              "  42.18067789077759),\n",
              " 'test_mae': array([0.68306577, 0.68693385, 0.6861118 , 0.68749153, 0.6859154 ]),\n",
              " 'test_rmse': array([0.87112753, 0.87435326, 0.87504156, 0.87586706, 0.87425932]),\n",
              " 'test_time': (1.9688711166381836,\n",
              "  2.0071260929107666,\n",
              "  1.761504888534546,\n",
              "  2.031903028488159,\n",
              "  1.7371511459350586)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-CtVKJIzGqB"
      },
      "source": [
        "- Root Mean Square Error of 0.8741 which is pretty good. \n",
        "\n",
        "- Now we can train on the dataset and arrive at predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29X9xV6uUNdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve the trainset.\n",
        "trainset = data.build_full_trainset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-UQf1vSUK2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a1a9094-ecf5-4dd7-b94e-113cb0c0207a"
      },
      "source": [
        "# Train the svd algorithm on full trainset.\n",
        "svd.fit(trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f63227cb828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5EsO2bOVzGqH"
      },
      "source": [
        "We'll pick again user with ID 1310 and check the ratings he has given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pWALy14yzGqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c6eef453-eebb-4464-9b01-5851c2e4fce3"
      },
      "source": [
        "ratings[ratings['user_id'] == 1310][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>215928</th>\n",
              "      <td>1310</td>\n",
              "      <td>2988</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215929</th>\n",
              "      <td>1310</td>\n",
              "      <td>1293</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215930</th>\n",
              "      <td>1310</td>\n",
              "      <td>1295</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215931</th>\n",
              "      <td>1310</td>\n",
              "      <td>1299</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215932</th>\n",
              "      <td>1310</td>\n",
              "      <td>2243</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        user_id  movie_id  rating\n",
              "215928     1310      2988       3\n",
              "215929     1310      1293       5\n",
              "215930     1310      1295       2\n",
              "215931     1310      1299       4\n",
              "215932     1310      2243       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oSVOIrStzGqJ"
      },
      "source": [
        "Now let's use SVD to predict the rating that User with ID 1310 will give to a random movie (let's say with Movie ID 1994)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZipkvLYzGqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06ffd23a-2178-42a6-9b15-f735545bffdd"
      },
      "source": [
        "svd.predict(1310, 1994)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(uid=1310, iid=1994, r_ui=None, est=3.656048520809981, details={'was_impossible': False})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jd8kpMtbzGqL"
      },
      "source": [
        "For movie with ID 1994, I get an estimated prediction of 3.656.\n",
        "\n",
        "The recommender system works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lY7r8EwzGqM"
      },
      "source": [
        "## Conclusion\n",
        "In this notebook, we attempted to build a model-based Collaborative Filtering movie recommendation sytem based on latent features from a low rank matrix factorization method called SVD. \n",
        "\n",
        "As it captures the underlying features driving the raw data, it can scale significantly better to massive datasets as well as make better recommendations based on user's tastes.\n",
        "\n",
        "However, we still likely lose some meaningful signals by using a low-rank approximation. \n",
        "\n",
        "Specifically, there's an interpretability problem as a singular vector specifies a linear combination of all input columns or rows. \n",
        "\n",
        "There's also a lack of sparsity when the singular vectors are quite dense. \n",
        "\n",
        "Thus, SVD approach is limited to linear projections."
      ]
    }
  ]
}